name: pr-workflow

on:
  pull_request:
    branches:
      - development
  workflow_dispatch:

jobs:
  build-us-west-2:
    runs-on: ubuntu-latest
    env:
      REGION: "us-west-2"
      VERSION: "2.0.5"
      EMAIL: ${{ secrets.INVITATION_EMAIL_RECIPIENT }}
    steps:
      - name: Check out pr branch
        uses: actions/checkout@v2
        with:
          ref: ${{ github.sha }}

      - name: Initialize AWS credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.BUILD_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.BUILD_AWS_SECRET_ACCESS_KEY }}
          invitation-email-recipient: ${{ secrets.INVITATION_EMAIL_RECIPIENT }}
          aws-region: us-west-2

      - name: Setup build environment
        run: |
          echo "SHORT_SHA=`git rev-parse --short HEAD`" >> $GITHUB_ENV
          DATETIME=$(date '+%s')
          echo "DIST_OUTPUT_BUCKET=media-insights-engine-frontend-$DATETIME" >> $GITHUB_ENV

      - name: Run build script
        run: |
          cd deployment
          aws s3 mb s3://$DIST_OUTPUT_BUCKET-$REGION --region $REGION
          ./build.sh ${DIST_OUTPUT_BUCKET}-${REGION} ${VERSION} ${REGION} | tee >( awk '/Without existing MIE deployment/{getline; print}' >template )

      - name: Deploy stack
        run: |
          cd deployment
          TEMPLATE=$(cat template | cut -f 2 -d "'")
          rm -f template
          STACK_NAME="pr${SHORT_SHA}"
          set -x
          aws cloudformation create-stack --stack-name $STACK_NAME --template-url $TEMPLATE --region $REGION --parameters ParameterKey=AdminEmail,ParameterValue=$EMAIL --capabilities CAPABILITY_IAM CAPABILITY_NAMED_IAM CAPABILITY_AUTO_EXPAND --disable-rollback
          aws cloudformation wait stack-create-complete --stack-name $STACK_NAME
          set +x
          WEBAPP_URL=$(aws cloudformation --region us-west-2 describe-stacks --stack-name $STACK_NAME --query "Stacks[0].Outputs[?OutputKey=='ContentAnalyisSolution'].OutputValue" --output text)
          # Make the WEBAPP_URL available to the next workflow step
          echo "WEBAPP_URL=${WEBAPP_URL}" >> $GITHUB_ENV

      - name: Clean build environment
        run: aws s3 rb s3://${DIST_OUTPUT_BUCKET}-${REGION} --force

      - name: Get login credentials
        run: |
          # Get the newest file in s3://github-test-bot
          NUM_EMAILS=$(aws s3 ls s3://github-test-bot | wc -l)
          # Iterate thru all the files in the s3 bucket until you find the invitation
          # email that references to our stack:
          for i in `seq 1 $NUM_EMAILS`; do
          INVITATION_EMAIL=$(aws s3api list-objects-v2 --bucket "github-test-bot" --query 'reverse(sort_by(Contents, &LastModified))['$((i-1))'].Key' --output=text)
          # Make sure it belongs to our stack
          aws s3 cp s3://github-test-bot/$INVITATION_EMAIL ./invitation_email --quiet
          STACK_NAME="pr${SHORT_SHA}"
          grep ":stack/${STACK_NAME}" ./invitation_email
          if [ $? -eq 0 ];
          then break; # we found the invitation email so quit looking
          fi;
          done;
          # Remove the invitation email from s3
          #aws s3 rm s3://github-test-bot/$INVITATION_EMAIL
          TEMP_PASSWORD=$(cat ./invitation_email | grep 'temporary password' | sed 's/.*password is \(.*\)<br>AWS.*/\1/')
          # Password may contain HTML entities, so decode them to characters
          TEMP_PASSWORD=$(echo $TEMP_PASSWORD | perl -MHTML::Entities -pe 'decode_entities($_);')
          # Make TEMP_PASSWORD available to the next workflow step
          echo "TEMP_PASSWORD=${TEMP_PASSWORD}" >> $GITHUB_ENV

      - name: Start workflow
        run: |
          STACK_NAME="pr${SHORT_SHA}"
          # Get the workflow api endpoint
          MIE_STACK_NAME=$(aws cloudformation list-stacks --query 'StackSummaries[?starts_with(StackName,`'$STACK_NAME'-MieStack`)].StackName' --output json --region $REGION | grep MieStack | cut -f 2 -d '"' | tail -n 1)
          WORKFLOW_API_ENDPOINT=$(aws cloudformation describe-stacks --stack-name "$MIE_STACK_NAME" --region $REGION --query "Stacks[0].Outputs[?OutputKey=='WorkflowApiEndpoint'].OutputValue" --output text)
          DATAPLANE_BUCKET=$(aws cloudformation describe-stacks --stack-name "$MIE_STACK_NAME" --region $REGION --query "Stacks[0].Outputs[?OutputKey=='DataplaneBucket'].OutputValue" --output text)
          # Upload a test video file
          wget -q https://vjs.zencdn.net/v/oceans.mp4
          aws s3 cp oceans.mp4 s3://${DATAPLANE_BUCKET}
          # Install an IAM enabled HTTP client
          pip install awscurl

          # ####################################
          # ###### TEST CasImageWorkflow  #######
          # ####################################
          # # TODO: upload TEST_IMAGE.png image file to dataplane bucket

          # # Get workflow configuration
          # WORKFLOW_NAME=CasImageWorkflow

          # # Disable faceSearch
          # WORKFLOW_CONFIGURATION=$(awscurl -X GET --region us-west-2 ${WORKFLOW_API_ENDPOINT}workflow/$WORKFLOW_NAME | cut -f 2 -d "'" | perl -pe 's/"Definition.+?}]}}}",//g' | jq '.Stages.RekognitionStage.Configuration' --compact-output)
          # WORKFLOW_CONFIGURATION=$(echo $WORKFLOW_CONFIGURATION | sed -e 's/"faceSearchImage":{"MediaType":"Image","Enabled":true}/"faceSearchImage":{"MediaType":"Image","Enabled":false}/')
          # WORKFLOW_CONFIGURATION='{"RekognitionStage":'$WORKFLOW_CONFIGURATION'}'

          # # Execute workflow
          # awscurl -X POST --region us-west-2 --data '{"Name":"CasImageWorkflow", "Configuration":'$WORKFLOW_CONFIGURATION', "Input":{"Media":{"Image":{"S3Bucket": "'${DATAPLANE_BUCKET}'", "S3Key":"TEST_IMAGE.png"}}}}' ${WORKFLOW_API_ENDPOINT}workflow/execution > curl.txt

          # # Wait until the workflow is done
          # WORKFLOW_ID=$(cat curl.txt | cut -f 2 -d "'" | perl -pe 's/"Definition.+?}]}}}",//g' | jq '.Id' --raw-output)
          # WORKFLOW_STATUS=$(awscurl -X GET --region us-west-2 ${WORKFLOW_API_ENDPOINT}workflow/execution/${WORKFLOW_ID} | cat | cut -f 2 -d "'" | perl -pe 's/"Definition.+?}]}}}",//g' | jq '.Status' --raw-output)
          # while [ "$WORKFLOW_STATUS" = "Started" ] || [ "$WORKFLOW_STATUS" = "Queued" ]; do sleep 1; WORKFLOW_STATUS=$(awscurl -X GET --region us-west-2 ${WORKFLOW_API_ENDPOINT}workflow/execution/${WORKFLOW_ID} | cat | cut -f 2 -d "'" | perl -pe 's/"Definition.+?}]}}}",//g' | jq '.Status' --raw-output); echo $WORKFLOW_STATUS; done

          ####################################
          ###### TEST CasVideoWorkflow #######
          ####################################
          WORKFLOW_NAME=CasVideoWorkflow

          # Disable faceSearch and GenericDataLookup operator
          set -x
          WORKFLOW_CONFIGURATION=$(awscurl -X GET --region us-west-2 ${WORKFLOW_API_ENDPOINT}workflow/$WORKFLOW_NAME | cut -f 2 -d "'" | perl -pe 's/"Definition.+?}]}}}",//g' | jq '.Stages.defaultVideoStage.Configuration' --compact-output)
          WORKFLOW_CONFIGURATION=$(echo $WORKFLOW_CONFIGURATION | sed -e 's/"faceSearch":{"MediaType":"Video","Enabled":true}/"faceSearch":{"MediaType":"Video","Enabled":false}/')
          WORKFLOW_CONFIGURATION=$(echo $WORKFLOW_CONFIGURATION | sed -e 's/"GenericDataLookup":{"MediaType":"Video","Enabled":true}/"GenericDataLookup":{"MediaType":"Video","Enabled":false}/')
          WORKFLOW_CONFIGURATION='{"defaultVideoStage":'$WORKFLOW_CONFIGURATION'}'
          echo "WORKFLOW_CONFIGURATION:"
          echo $WORKFLOW_CONFIGURATION

          # Execute workflow
          awscurl -X POST --region us-west-2 --data '{"Name":"CasVideoWorkflow", "Configuration":'$WORKFLOW_CONFIGURATION', "Input":{"Media":{"Video":{"S3Bucket": "'${DATAPLANE_BUCKET}'", "S3Key":"oceans.mp4"}}}}' ${WORKFLOW_API_ENDPOINT}workflow/execution > curl.txt

          # Wait until the workflow is done
          WORKFLOW_ID=$(cat curl.txt | cut -f 2 -d "'" | perl -pe 's/"Definition.+?}]}}}",//g' | jq '.Id' --raw-output)
          WORKFLOW_STATUS=$(awscurl -X GET --region us-west-2 ${WORKFLOW_API_ENDPOINT}workflow/execution/${WORKFLOW_ID} | cat | cut -f 2 -d "'" | perl -pe 's/"Definition.+?}]}}}",//g' | jq '.Status' --raw-output)
          set +x
          while [ "$WORKFLOW_STATUS" = "Started" ] || [ "$WORKFLOW_STATUS" = "Queued" ]; do sleep 10; WORKFLOW_STATUS=$(awscurl -X GET --region us-west-2 ${WORKFLOW_API_ENDPOINT}workflow/execution/${WORKFLOW_ID} | cat | cut -f 2 -d "'" | perl -pe 's/"Definition.+?}]}}}",//g' | jq '.Status' --raw-output); echo -n '.'; done
          echo $WORKFLOW_STATUS

      - name: Start puppeteer
        # The checkout action above changes the work dir in a way that breaks
        # the docker commands in this action, so we need to specify work dir
        # explicitly here.
        working-directory: /home/runner/work/
        run: |
          TEMP_PASSWORD="${{ env.TEMP_PASSWORD }}"
          WEBAPP_URL=${{ env.WEBAPP_URL }}
          echo "Downloading puppeteer tests"
          git clone https://github.com/iandow/aws-media-insights-puppeteer
          cd aws-media-insights-puppeteer
          npm i puppeteer puppeteer-screenshot-tester --quiet
          docker build --tag=cas-puppeteer:latest .
          docker run --rm -v "$PWD":/usr/src/app -e WEBAPP_URL="${WEBAPP_URL}" -e TEMP_PASSWORD="${TEMP_PASSWORD}" cas-puppeteer:latest
